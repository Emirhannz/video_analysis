

# ğŸš§ DetaylÄ± Issue Listesi

## âœ… **Issue 1: Bounding Box Tracker (DeepSORT veya SORT) Optical Flow'a Entegrasyonu**

**AmaÃ§:**
Mevcut optical flow yÃ¶ntemini gÃ¼Ã§lendirmek, hareketli altyazÄ±larÄ± daha net ve tutarlÄ± takip etmek.

### ğŸ“ YapÄ±lacaklar:

* [ ] **1. SORT SeÃ§imi ve YÃ¼kleme:**

 sort.py dosyasÄ±nÄ± projeye yÃ¼kledik ve gerekli kÃ¼tÃ¼ÄŸhaneleri kurduk. incele



* [ ] **2. SORT Tracker'Ä±n Projeye Entegrasyonu:**

  * Tracker'Ä± frame bazÄ±nda Ã§alÄ±ÅŸtÄ±ran wrapper class oluÅŸtur:

    ```python
    class BoundingBoxTracker:
        def __init__(self):
            self.tracker = Sort()  # SORT tracker instance oluÅŸtur
        
        def update(self, detections):
            # detections: [[x1, y1, x2, y2, confidence], ...]
            tracked_boxes = self.tracker.update(np.array(detections))
            return tracked_boxes
    ```

* [ ] **3. Optical Flow Tracker ile SORT Tracker'Ä± BirleÅŸtir:**

  * Optical Flow Tracker (`process_frame`) iÃ§ine SORT tracker eklenmeli:

    * Her OCR algÄ±lanan kutu SORT trackerâ€™a input olarak verilmeli.
    * Her frame iÃ§in `BoundingBoxTracker.update()` Ã§aÄŸrÄ±larak kutu takibi yapÄ±lmalÄ±.
    * SORTâ€™dan dÃ¶nen kutularÄ±n koordinatlarÄ±yla Optical Flow'dan gelen kutular birleÅŸtirilmeli.

* [ ] **4. Ã‡Ä±ktÄ±larÄ± Test Et ve Optimize Et:**

  * Trackerâ€™larÄ±n performansÄ±nÄ± birkaÃ§ farklÄ± video ile test et.
  * SonuÃ§larÄ±n tutarlÄ±lÄ±ÄŸÄ±na gÃ¶re tracker parametrelerini ayarla.

---

## âœ… **Issue 2: SpaCy NLP Pipeline'Ä±nÄ±n SÄ±fÄ±rdan KurulmasÄ± ve TÃ¼m CÃ¼mlelerin Analiz Edilmesi**

**AmaÃ§:**
SpaCy NLP pipeline'Ä±n etkin Ã§alÄ±ÅŸmasÄ±nÄ± saÄŸlamak ve cÃ¼mlelerin detaylÄ± analiz edilerek entity extraction ve POS tagging yapÄ±lmasÄ±.

### ğŸ“ YapÄ±lacaklar:

* [ ] **1. Mevcut SpaCy ve Hugging Face KontrolÃ¼**

  Kontrol ettik- baÅŸarÄ±lÄ±



* [ ] **2. SpaCy Pipeline SÄ±nÄ±fÄ±nÄ± Yeniden OluÅŸtur:**

  ```python
  import spacy

  class NLPProcessor:
      def __init__(self):
          self.nlp = spacy.load("tr_core_news_trf")
      
      def analyze_sentence(self, sentence):
          doc = self.nlp(sentence)
          entities = [{'text': ent.text, 'label': ent.label_} for ent in doc.ents]
          pos_tags = [{'text': token.text, 'pos': token.pos_, 'lemma': token.lemma_} for token in doc]
          return {
              'entities': entities,
              'pos_tags': pos_tags
          }
  ```

* [ ] **3. TÃ¼m CÃ¼mlelerin NLP Analizinden GeÃ§irilmesi:**

  * `VideoAnalyzer` iÃ§indeki cÃ¼mle iÅŸlemede ÅŸu Ã¶rneÄŸi kullan:

  ```python
  nlp_processor = NLPProcessor()

  for sentence in completed_sentences:
      analysis = nlp_processor.analyze_sentence(sentence['text'])
      sentence['entities'] = analysis['entities']
      sentence['pos_tags'] = analysis['pos_tags']
  ```

* [ ] **4. SonuÃ§larÄ± Test Et ve Entity Ã‡Ä±karÄ±mÄ±nÄ± DoÄŸrula:**

  * BirkaÃ§ Ã¶rnek metin Ã¼zerinde entity ve POS taglerini kontrol et:

  ```python
  sentence = "CumhurbaÅŸkanÄ± ErdoÄŸan Ankara'da konuÅŸtu."
  analysis = nlp_processor.analyze_sentence(sentence)
  print(analysis['entities'])  # [{'text': 'ErdoÄŸan', 'label': 'PERSON'}, {'text': 'Ankara', 'label': 'LOC'}]
  ```

---

## âœ… **Issue 3: NLP TabanlÄ± CÃ¼mle Tamamlama ve Sentence Buffer MekanizmasÄ±nÄ±n GeliÅŸtirilmesi**

**AmaÃ§:**
Sentence Buffer mekanizmasÄ±nÄ±n NLP destekli daha akÄ±llÄ± Ã§alÄ±ÅŸmasÄ±, daha doÄŸru ve mantÄ±klÄ± cÃ¼mlelerin Ã¼retilmesi.

### ğŸ“ YapÄ±lacaklar:

* [ ] **1. Hugging Face Transformer ile TÃ¼rkÃ§e Modeli SeÃ§ ve Kur:**

  * Tavsiye edilen model: [mT5-small Turkish](https://huggingface.co/google/mt5-small)

  ```bash
  pip install transformers sentencepiece
  ```

* [ ] **2. NLP Destekli SentenceBuffer Class'Ä± OluÅŸtur:**

  ```python
  from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

  class NLPEnhancedSentenceBuffer:
      def __init__(self, model_name="google/mt5-small"):
          self.buffer = ""
          self.tokenizer = AutoTokenizer.from_pretrained(model_name)
          self.model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

      def add_text(self, text):
          self.buffer += " " + text.strip()
          sentences = self._complete_sentences()
          return sentences

      def _complete_sentences(self):
          inputs = self.tokenizer.encode("tamamla: " + self.buffer, return_tensors="pt")
          outputs = self.model.generate(inputs, max_length=100)
          result = self.tokenizer.decode(outputs[0], skip_special_tokens=True)

          # cÃ¼mle sonunu bul ve buffer'Ä± temizle
          if result.endswith(('.', '?', '!')):
              self.buffer = ""
              return [result.strip()]
          return []
  ```

* [ ] **3. Yeni Bufferâ€™Ä± VideoAnalyzerâ€™e Entegre Et:**

  * Mevcut buffer yerine NLP destekli buffer'Ä± Ã§aÄŸÄ±r:

  ```python
  self.sentence_buffer = NLPEnhancedSentenceBuffer()
  completed_sentences = self.sentence_buffer.add_text(frame_text)
  ```

* [ ] **4. SonuÃ§larÄ± Test Et ve Optimize Et:**

  * Ã‡eÅŸitli videolarda oluÅŸan cÃ¼mleleri incele.
  * CÃ¼mle tamamlama baÅŸarÄ±sÄ±nÄ± deÄŸerlendir ve gerekli ayarlamalarÄ± (Ã¶rneÄŸin max\_length veya tokenizer parametreleri) yap.

---

## ğŸ“Œ **Ekip iÃ§in Son Not:**

* Bu issue listesindeki her adÄ±m titizlikle uygulandÄ±ÄŸÄ±nda, NLP ve takip problemlerinin Ã§Ã¶zÃ¼leceÄŸini net olarak gÃ¶receksiniz.
* SpaCy modeli dÃ¼zgÃ¼n yÃ¼klenmiÅŸse tekrar yÃ¼klenmesi gerekmez. Mevcut SpaCyâ€™nin doÄŸruluÄŸu ve etkin kullanÄ±mÄ± Ã¼zerine odaklanmanÄ±z yeterli olacaktÄ±r.
* TÃ¼rkÃ§e karakter dÃ¼zeltmeleri, OCR iyileÅŸtirmeleri gibi diÄŸer iÅŸler **bu listedeki adÄ±mlar tamamlandÄ±ktan sonra** ayrÄ±ca ele alÄ±nmalÄ±dÄ±r.


